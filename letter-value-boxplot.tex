\documentclass[oneside]{article}
\usepackage{fullpage}

\usepackage{hyperref}
\usepackage{booktabs}
\usepackage[format=plain,font=small]{caption}
\usepackage[small]{titlesec}
\usepackage[round,sectionbib]{natbib}
\usepackage{setspace}
\renewcommand\rmdefault{bch}
\linespread{1.1} 
\usepackage{amssymb}
\newcommand{\Reals}{{\rm I\kern-.1667em{}R}}
\usepackage[pdftex]{graphicx}
\DeclareGraphicsExtensions{.png,.pdf}
\graphicspath{{images/}}

\title{Letter-value plots: Boxplots for large data}
\author{\begin{tabular}[t]{c c c }
  Heike Hofmann         & Karen Kafadar         & Hadley Wickham \\
  Dept of Statistics    & Dept of Statistics    & Dept of Statistics \\
  Iowa State University & Indiana University    & Rice University \\
  Ames, IA 50011        & Bloomington, IN 47408 & Houston, TX 77001
\end{tabular}}

\begin{document}
\maketitle

\begin{abstract}

  Conventional boxplots \citep{eda} are useful displays for conveying rough
  information about the central 50\% of and the extent of the data. For
  small-sized data sets ($n < 200$), detailed estimates of tail behavior
  beyond the quartiles may not be trustworthy, so the information provided by
  boxplots is appropriately somewhat vague beyond the quartiles, and the
  expected number of ``outliers'' of size $n$ is often less than 10
  \citep{dchbox}. Larger data sets ($n \approx 10,000-100,000$) afford more
  precise estimates of quantiles in the tails beyond the quartiles.
  Conventional boxplots do not show this information about the tails, and, in
  addition, show large numbers of extreme, but not unexpected, observations
  (about $0.4 + 0.007n$ for a sample from a Gaussian population).

  The letter-value plot addresses both these shortcomings: (1) it conveys
  more detailed information in the tails using letter values, only to the
  depths where the letter values are reliable estimates of their corresponding
  quantiles and (2) ``outliers'' are labeled as those observations beyond the
  most extreme letter value shown. All features shown on the letter-value
  boxplot are actual observations, thus remaining faithful to the principles
  that governed Tukey's original boxplot. We illustrate letter-value plots
  with some actual examples that demonstrate their usefulness, particularly
  for large data sets. All graphics are created using R \citep{R2011}, and
  code is made available in the supplementary materials.

  \textbf{Key words}: boxplots, quantiles, letter value display, 
  fourth, order statistics, tail area.
  
\end{abstract}

\section{Introduction}

Boxplots \citep{tukey:1970,tukey72} give a compact graphical summary of the distribution of a variable, based around a set of order statistics called letter values. In \textit{Exploratory Data Analysis}, \citet{eda} recommended the $([n/2] + 1)/2$-th and $(n + 1 - ([n/2] + 1)/2)$-th order statistics as estimates of the quartiles, the ``lower fourth'' and ``upper fourth'' in \citet{ureda} with \textit{depth} $([n/2] + 1)/2$ because they lie that many observations in from the extremes.  

% Since John Tukey introduced boxplots, various modifications to them have been proposed, some by Tukey himself; e.g., the whisker definition changed from ``quartiles to extremes'' \citep{tukey72} to ``quartiles to adjacent values'' \citep{eda}. 

% \citet{variations.boxplots} enhanced boxplots with variable widths (proportional to the square root of the sample size) and notches (indicating half-lengths of approximate intervals for comparing medians). 

Boxplots are one of the few statistical graphics invented in the 20th century that have gained widespread adoption. Despite their widespread use, they are not without their problems, particularly for large datasets. There are two problems with boxplots when applied to large datasets: (1) the number of ``outliers'' grows linearly with the sample size and (2) estimates of tail behaviour are not displayed, despite the fact that larger sample sizes allow us to estimate reliably further out into the tails. Figure~\ref{fig:internet-bp} illustrates both problems with a boxplot of 135,605 internet (log-transformed) session durations, stratified into 32 groups based on the logarithm of the number of bytes transferred during the session. See \citet{kw06} for further details about the data and transformations. The sample sizes in the 32 boxes range from 1341 (box \#32) to 7865 (Box \#13), with a median sample size of 4238. With so many observations in each category, the number of labeled outliers is huge: far too many to investigate individually, and it is difficult to distinguish between extreme values and true outliers.

\begin{figure}[hbtp]
  \centering
  \includegraphics[width=\linewidth]{box2}

  \caption{Notched boxplots \citep{variations.boxplots} of (log-transformed)
  duration for 135,605 internet sessions, grouped by ranges of
  (log-transformed) byte lengths for the sessions.}

  \label{fig:internet-bp} 
\end{figure}

An observation is labelled as an ``outlier'' and displayed individually if it lies at or beyond the inner fences \citep{eda,emerson83}, defined as $[L_F - k(U_F - L_F), U_F + k(U_F - L_F)]$ where $L_F$ and $U_F$ denote the lower and upper fourths and typically $k = 1.5$. Despite the name, these ``outliers'' may be either (a) genuine, but extreme, observations from same the distribution as the bulk of the data; or (b) true outliers, observations from a different distribution. The boxplot tends to display too many ``outliers'', as judged by looking at boxplots of Gaussian data. There the expected number of ``outliers'' grows approximately linearly with $n$: the theoretical fourths from a sample of independent Gaussian observations are $\pm 0.6745\sigma$, yielding an interquartile range of 1.35$\sigma$, and inner fences at $\pm (0.675 + 1.5 \cdot 1.35)\sigma = \pm 2.70\sigma$. Therefore the box and whiskers covers 99.3\% of the distribution, leaving about 0.7\% of the points to be labeled as ``outliers'' (cf.~\citet{dchlv}). Similarly, the probability of getting at least one ``outlier'' for Gaussian data is high: over 30\% for samples of size 50, and 97\% for samples of size 500 \citep[pg. 1148]{dchbox}. One way to reduce the number of ``outliers'' is to increase $k$, but a single value of $k$ cannot work for all sample sizes \citep[pg. 1148]{dchbox}.

Displaying only two fixed letter values (the upper and lower fourths) has two problems: (1) for very small samples sizes these estimates will have high standard error and may be misleading, (2) for large datasets, many more letter values can be reliably estimated to give more information about the tails. 

% The conventional boxplot is very useful for small or moderate-sized data sets, but is somewhat inadequate for very large data sets, in two ways. First, although estimates of quantiles in the tails of a distribution beyond the quartiles may be imprecise for smaller data sets (and thus probably better not shown), large data sets afford somewhat more reliable estimates of tail behavior. Second, because the expected ``some outside rate per sample'' already exceeds 99\% when $n = 700$, the conventional boxplot can be expected to label increasing numbers of observations as ``outliers''. The letter-value boxplot that we propose addresses both shortcomings for large data sets. In addition, its construction resembles the original boxplot by displaying only actual values that occur in the sample. The rules for constructing the letter value boxplot result in a display very similar to the conventional boxplot for moderate sized data sets.

Letter-value plots are a variation of boxplots that replace the whiskers with a variable number of letter values, selected based on the uncertainty associated with each estimate and hence the number of observations. Any values outside the most extreme letter value are displayed individually. These two modifications reduce the number of ``outliers'' displayed for large datasets, and make letter-value plots useful over a much wider range of data sizes. Letter-value plots remain true to the spirit of boxplots by only displaying actual observations from the sample, and remaining free of tuning parameters. Figure~\ref{fig:internet-lbp} shows the same data as a letter-value plot, which better shows the skewed tails (even with the logarithmic transformations) and far fewer ``labeled'' outliers. Letter-value plots are described in detail in Section~\ref{sec:lv-boxplots}

Section~\ref{sec:extent} discusses rules to proposes a number of potential rules to select the letter values based on the sample size. For the letter-value plot, we select a rule that chooses the letter values based on their associated sampling error: confidence intervals for letter values should not overlap adjacent letter values.

\begin{figure}[hbtp]
  \centering
  \includegraphics[width=\linewidth]{lvbox2}

  \caption{Letter-value plots of (log-transformed) duration for 135,605
  internet sessions, grouped by ranges of (log-transformed) byte lengths for
  the sessions.}

  \label{fig:internet-lbp} 
\end{figure}

% In the setting of an exponential distribution with unit mean, the theoretical hinges lie at 0.2877 and 1.3863, so the fourth spread will be roughly 1.0986. The box and whiskers therefore cover less area, roughly 0.9519, and an ``outlier'' rate of almost 5\%.

% \citet[pg. 1148]{dchbox} demonstrated that the conventional boxplot (using a slightly improved definition of the fourths, namely that order statistic (or average of adjacent order statistics) having depth $n/4 + 5/12$, has a ``some outside rate per sample'' (i.e., the proportion of Gaussian samples that have at least 1 labeled outlier) that exceeds 30\% even for samples of size $n = 50$ and 97\% for samples of size 500. They found that values of $k$ between 2.2 and 2.4 kept the ``some outside rate per sample'' down to 5\% for samples of size $n$ up to 300. Much larger values of $k$ are needed for samples of size 100,000, from which conventional boxplots can be expected to label 700 observations, far too many for detailed inquiry, especially when, for truly Gaussian samples, such labeled ``outliers'' are consistent with the underlying distribution.

% The approach of \citet{dchbi}, which labels a fixed number of ``outliers'' (``fixed outside rate'') using a rule that is based on the fourths, avoids this dependence of the expected outside rate on the underlying distribution. Although it avoids the linear dependence of number of ``outliers'' on $n$, it also fails to display any interesting features in the tails. The letter value plot displays such features using data-determined letter values. 

There have been other attempts to overcome these problems with boxplots, such as vase \citep{vase}, violin \citep{violin}, and box-percentile plots \citep{box.percentiles}. These display more detailed information about the distributions, through the use of nonparametric density estimates, which is especially useful for larger sample sizes. However, as \citet{vase} acknowledged, these displays depend on the specific estimation procedure (e.g., kernel density estimate) as additional smoothing parameters. Thus, these displays can be different for the same data set, depending on the density estimate or smoothing parameters. This makes these plots less suitable for a first exploratory visualisation as multiple tuning parameters need to be adjusted.

Some proposals for multivariate data and final discussion appears in Sections~\ref{sec:bivariate} and~\ref{sec:summary}.

We have made our implementation of letter-value plots available as an R package, \texttt{lvplot}, available from {\sc cran}. All code and data used to produce the plots in this paper is available in the online supplementary material.

\section{Letter values}
\label{sec:letter-values}

Let $X_{(1)}$, ... $X_{(n)}$ denote the order statistics from a sample of size $n$. Per conventional notation, let $\lfloor y \rfloor$ and $\lceil y \rceil$ denote the greatest integer below $y$ and the next integer above $y$, respectively. The letter values are those order statistics having specific depths, defined recursively starting with the median. The depth of the median, $d_1$, of a sample of size $n$ is defined as $d_1 = (1 + n )/2$; the depths of successive letter values (F = fourths, E = eighths, D = sixteenths, C = thirty-seconds, ...) are defined recursively as $d_i = (1 + \lfloor d_{i-1} \rfloor)/2$. (We also will use the letter value itself as the subscript to the notation for depth; e.g., both $d_1$ and $d_M$ denote the depth of the median.) The $i^{th}$ lower and upper letter values ($LV_i$) are thus defined as $L_i = X_{(d_i)}$ and $U_i = X_{(n - d_i + 1)}$. (If the depth is an integer plus $\frac{1}{2}$, then the lower letter value is defined as the average of the two adjacent order statistics, $X_{(\lfloor d_i \rfloor)}$ and $X_{(\lceil d_i \rceil)}$, and similarly for the upper letter value.) The advantage of this definition for the letter values is that the median of the sampling distribution for this sample quantile from a continuous distribution $F(\cdot)$ is very close to $F^{-1} ((i - \frac{1}{3})/(n + \frac{1}{3})$, for a wide range of $F$, $n$, and $i$ \citep{dchlv}. Because each depth is roughly half the previous depth, the letter values approximate the quantiles corresponding to tail areas $2^{-i}$.

The ``labeled outlier rule'' for conventional boxplots relies on the fourths because the rule is then ``unlikely to be adversely affected by extreme observations'' and ``to minimize the difficulties of masking'' \citep[pg. 992]{dchbox}. Conventional boxplots rely on the fourths to ensure insensitivity to the rule governing outlier labeling. Hence, the breakdown point of default boxplots is 25\%; i.e., only if 25\% or more of the data values, all unfavorably located in one of the tails, are contaminated, will the summary statistics and outlier identification change. This high breakdown is one of the valuable features of boxplots. Moreover, the relatively low uncertainty in the fourths as estimates of the quartiles argues for using the fourths in the rule for labeling ``outliers'': the standard deviation of the fourths in a Gaussian population equals roughly $[(0.25 \cdot 0.75) / (n \phi(\Phi^{-1}(0.25)))]^{1/2} \sigma$ = $1.362 \sigma / \sqrt{n}$ or a 2-SD uncertainty of roughly 0.25$\sigma$ for Gaussian samples of size 120 \citep{ha.order}. Estimates of the population quantiles beyond the quartiles, when based on order statistics, are increasingly variable; e.g., for the same $n = 100$ sample, the 2-SD uncertainty in the eighths (depth = 13) and sixteenths (depth = 7) is approximately $ 2 \times 1.607 \sigma / \sqrt{n}$ = $0.32 \sigma$ and $ 2 \times 1.968 \sigma / \sqrt{n}$ = $0.40 \sigma$, respectively. Table~\ref{tbl:letter-values} shows these factors for the standard error formula, \texttt{SEfactor}, for the first 20 letter values, as well as the factor in increase in sample size needed for successive letter values to have the same uncertainty as the fourth. (For example, the fourths in a sample of size 120 have a 2-SD uncertainty of 0.25$\sigma$; we would need a sample of size 1.4$\cdot$120 = 168 for the eighth to have this same level of uncertainty.) For small samples, then, restricting attention to estimates of only the population median and quartiles, with some general indication of the tail length beyond the quartiles, is likely to be about all the information that the data can reliably support.

\begin{table}[htpb]
  \centering
  \begin{tabular}{llr@{.}lrrr}
  \toprule
  LV & tail area & \multicolumn{2}{l}{rough \%} & $2^j$ & SEfactor & n-equiv*\\ \midrule
   M & .50 & 50&0\% & 2 & 1.253314 \\
   F & .25 & 25& 0\% & 4 & 1.362633 & 1.0\\
   E & .125 & 12& 5\% & 8 & 1.606574 & 1.4\\
   D & .0625 & 6& 25\% & 16 & 1.968236 & 2.1\\
   C & .03125 & 3&13\% & 32 & 2.472133 & 3.3\\
   B & .015625 & 1&56\% & 64 & 3.162020 & 5.4\\
   A & .0078125 & 0&8\% & 128 & 4.101274 & 9.1\\
   Z & .00390625 & 0&4\% & 256 & 5.378300 & 15.6\\
   Y & .001953125 & 0&2\% & 512 & 7.115270 & 27.3\\
   X & .0009765625 & 0&1\% & 1,024 & 9.480641 & 48.4\\
   W & .00048828125 & 0&05\% & 2,048 & 12.706667 & 87.0  \\
   V & .000244140625 & 0&024\% & 4,096 & 17.113727 & 157.7\\
   U & .0001220703125 & 0&012\% & 8,192 & 23.144119 & 288.5\\
   T & .00006103515625 & 0&006\% & 16,384 & 31.408968 & 531.3\\
   S & .000030517578125 & 0&003\% & 32,768 & 42.753381 & 984.4\\
   R & .0000152587890625 & 0&0015\% & 65,536 & 58.346982 & 1833.5\\
   Q & .00000762939453125 & 0&0008\% & 131,072 & 79.808978 & 3430.5\\
   P & .000003814697265625 & 0&0004\% & 252,144 & 109.387241 & 6444.3\\
   O & .0000019073486328125 & 0&0002\% & 504,288 & 150.193933 & 12149.2\\
   N & .00000095367431640625 & 0&0001\% &1,008,576 & 206.552719 & 22977.6\\
  \bottomrule
  \end{tabular}

  \caption{First 20 letter values. Note: \texttt{tail area} is $2 ^{-i}$, $i =
  1, ..., 20$; \texttt{rough}\% rounds $2 ^{-i} \times 100$\% to the first 1
  or 2 nonzero digits; \texttt{odds} expresses tail area as \texttt{1 in}
  $2^i$; ` \texttt{SEfactor} gives the factor for the asymptotic standard
  error of the order statistic (from a Gaussian population, variance
  $\sigma^2$) corresponding to \texttt{tail area}, i.e., $SE(LV) \approx$
  \texttt{SEfactor} $\times \sigma / \sqrt{n}$, where \texttt{SEfactor} =
  $\sqrt{p_i (1-p_i)} / \phi(\Phi^{-1}(p_i))$, $p_i$ = \texttt{tail area} =
  $2^{-i}$. \texttt{n-equiv} = (\texttt{SEfactor}/1.362633)$^2$ which gives
  the factor of increase in sample size for the uncertainty in that letter
  value to be the same as that for the fourth (e.g., need 1.4$n$
  (respectively, 2.1$n$) observations for the eighth (respectively, sixteenth)
  to have the same uncertainty as that of a fourth from a sample of size $n$.
  }
  \label{tbl:letter-values}
\end{table}

% Table~\ref{tbl:counties} illustrates the letter values of the 1980 populations
% and the log populations of the 3068 counties in the continental United States.
% Along with the letter values are shown the midsummaries (average of the upper
% and lower letter values, denoted ``mids'' in Table 2), the midspreads (spread
% between the letter values, denoted ``spread''), and ``pseudo-sigma''
% \citep[pg. 40]{dchlv}, the sample letter-value spread divided by the
% theoretical letter-value spread for a standard Gaussian distribution (e.g.,
% pseudo-sigma based on the fourths is the fourth spread divided by 1.3490). For
% a symmetric population, the midsummaries should be constant, and, for a
% distribution with Gaussian-like tails, the pseudo-sigmas also should be fairly
% stable. Both the midsummaries and the pseudo-sigmas are much more nearly
% constant for the log populations than for the untransformed populations.
% 
% \begin{verbatim}
%                      Table 2
%            Letter value display for 1980
%          populations in 3068 U.S. counties
% 
%     Depth  Lower   Upper      Mid  Spread   pseudo-s
% M  1534.5  218.0   218.0   218.00     0.0     0.0000
% F   767.5  105.0   511.0   308.00   406.0   601.9365
% E   384.0   65.0  1082.0   573.50  1017.0   884.0792
% D   192.5   39.0  2280.0  1159.50  2241.0  1460.7718
% C    96.5   25.0  4572.0  2298.50  4547.0  2441.0384
% B    48.5   17.5  6641.5  3329.50  6624.0  3075.3878
% A    24.5   10.5  9694.5  4852.50  9684.0  4005.6933
% Z    12.5    8.0 14742.5  7375.25 14734.5  5539.1452
% Y     6.5    6.5 18972.5  9489.50 18966.0  6572.5570
% X     3.5    4.5 38316.0 19160.25 38311.5 12369.4452
% W     2.0    4.0 70716.0 35360.00 70712.0 21446.1187
% V     1.5    2.5 72745.5 36374.00 72743.0 20860.5759
% U     1.0    1.0 74775.0 37388.00 74774.0 20383.6663
% 
%              Letter value display for 1980
%          log populations in 3068 U.S. counties
% 
%     Depth  Lower   Upper      Mid  Spread   pseudo-s
% M  1534.5 2.3385  2.3385   2.3385  0.0000     0.0000
% F   767.5 2.0212  2.7084   2.3648  0.6872     1.0189
% E   384.0 1.8129  3.0342   2.4236  1.2213     1.0617
% D   192.5 1.5911  3.3579   2.4745  1.7669     1.1517
% C    96.5 1.3979  3.6601   2.5290  2.2622     1.2144
% B    48.5 1.2429  3.8223   2.5326  2.5794     1.1976
% A    24.5 1.0207  3.9865   2.5036  2.9658     1.2268
% Z    12.5 0.9031  4.1685   2.5358  3.2654     1.2276
% Y     6.5 0.8116  4.2780   2.5448  3.4664     1.2013
% X     3.5 0.6505  4.5512   2.6009  3.9007     1.2594
% W     2.0 0.6021  4.8495   2.7258  4.2475     1.2882
% V     1.5 0.3010  4.8616   2.5813  4.5606     1.3078
% U     1.0 0.0000  4.8738   2.4369  4.8738     1.3286
% \end{verbatim}

Letter values are particularly useful for large data sets, because (a) much of the most valuable information, especially for inference purposes, is contained in the tails (cf.\ Winsor's principle, ``All distributions are normal in the middle''; \citep[pg. 457]{tukey60}); and (b) adjacent letter values have asymptotic correlation $\sqrt{1/2}$ = 0.707 (\citet{mosteller46} cited by \citet[pg. 51--52]{dchlv}. Thus, rather little information concerning tail behavior is lost by considering only the letter values. Figure~\ref{qqpop4} illustrates this retention of tail information in visualizing the distribution of the populations and their logarithms in 3068 continental U.S. counties in 1980 via normal quantile-quantile (QQ) plots (panels A and B, respectively) versus using only the 25 letter values shown in Tables 1 and 2 above (panels C and D, respectively); the bottom panels (letter values only) reveal the advantage of logarithms as well as the top panels (full data set).

\begin{figure}[hbtp]
  \centering
  \includegraphics[width = 0.75 \linewidth]{counties-qq}

  \caption{QQ plots on 3068 Continental U.S. county populations (A) and their
  logarithms (B), versus QQ plots (C), (D) using only 25 letter values.}
  \label{qqpop4}
\end{figure}

\section{Letter-value plots}
\label{sec:lv-boxplots}

Letter-value plots are based on the letter-value statistics, with one box for each pair of lower and upper letter-values. The median is shown by a vertical line segment, and the innermost box is drawn at the lower and upper fourths, as in the conventional boxplot. An incrementally narrower box is drawn between at the lower and upper eighths, and narrower one still at the lower and upper sixteenths. We continue in this fashion until we reach a box that corresponds to a stopping rule described in the following section; beyond the most extreme box, all observations beyond these limits are identified as individual points. In practice, the software for creating this display proceeds from the outermost box to the innermost (``fourths'') box, so the innermost boxes are shaded more heavily, indicating a higher data density. Boxes with matching heights correspond to the same depths. With this definition, the expected proportion of the sample beyond the end of a box (roughly $1/2^i$) equals the expected proportion between this end and the end of the next bigger box (i.e., roughly $1/2^{i-1} - 1/2^i$ = $(1/2^{i-1})(1 - \frac{1}{2})$ = $1 / 2^i$). When $d_i$ reaches $\log_2 n$, the letter values are the extremes (minimum and maximum).

Letter-value plots for three different distributions are shown in Figure~\ref{stackbox}. Each panel displays a sample of 10,000 data points (top = standard Gaussian, middle = exponential with mean 1, bottom = standard uniform), first using the proposed letter-value plot up to letter Y, corresponding roughly to tail area $2^{-9}$ = 1/512 (top row), and then with the the conventional boxplot (bottom row). Comparing the left (Gaussian) and right (Uniform) letter value displays, overall \textit{more heavily shaded} displays correspond to distributions with \textit{lighter} tails. This phenomenon is shown more forcefully in Figure~\ref{t-dist} with letter-value plot for three heavy-tailed distributions: 10,000 samples from a $t$ distribution with 2, 3, 9 degrees of freedom (top rows) and the corresponding boxplots (bottom rows).

\begin{figure}[hbtp]
  \centering
  \includegraphics[width = \linewidth]{boxplots}

  \caption{Letter-value plots (top row) and standard boxplots (bottom
  row) for data from three different distributions. Each plot shows 10,000
  data points. From left to right, samples come from $N(0,1)$, $Exp_1$, and
  $U[0,1]$. }
  \label{stackbox}
\end{figure}

\begin{figure}[hbtp]
  \centering
%  \includegraphics[width = 0.75\linewidth]{tplot2kk}
  \includegraphics[width = \linewidth]{t-dist}
  
  \caption{Letter-value plots and standard boxplots for samples of 10,000
  for $t$ distributions on 2, 3, 9 degrees of freedom. Top row: Letter-value
  boxplots. Bottom row: Conventional boxplots.}
  \label{t-dist}
\end{figure}

Figure~\ref{lvpops} shows the letter-valuelue boxplots and the conventional boxplots for the 1980 populations and log populations of the 3068 counties in the United States. While the skewness in the distribution of the populations is evident from both the letter-value plot and the conventional boxplot, the former shows more clearly that the right tail of the log populations above the median is somewhat more extended than the left tail below the median (i.e., the boxes to the right of the median are slightly longer than those to the left of the median).

\begin{figure}[hbtp]
  \centering
%  \includegraphics[scale=.5]{lvpops}
 	\includegraphics[scale=.5]{counties-lvpop-a.pdf}
 	\includegraphics[scale=.5]{counties-lvpop-c.pdf}
 	\includegraphics[scale=.5]{counties-lvpop-b.pdf}
 	\includegraphics[scale=.5]{counties-lvpop-d.pdf}
 
  \caption{Letter-value plots and standard boxplots for the 1980
  populations and log populations of 3068 counties in the continental United
  States.}
  \label{lvpops} 
\end{figure}

\section{Extent of letter-value plots}
\label{sec:extent}

%As indicated in the introduction, a serious drawback to the conventional boxplot for large data sets is the tendency for a very large number of labeled outliers, roughly 0.7\% of the sample size. Figure~\ref{kkewbox} shows a boxplot of a measure of the duration of 135,000 Internet sessions, stratified into 32 groups based on the logarithms of the number of bytes transferred during the session (cf.~\citet{kw06}, for a similar plot). The sample sizes in the 32 boxes range from 1341 (Box\#32) to 7865 (Box\#13), with an average sample size of 4238. With so many observations in each category, the number of labeled outliers is huge --- far too many to investigate individually. This large number makes it difficult to distinguish between genuine ``outliers'' (observations from a different distribution) and merely extreme observations from a distribution with longer tails than the Gaussian.

%\begin{figure}[htbp]
%  \centering
%  \includegraphics[width = 0.75\linewidth]{lvbox2}

%  \caption{Letter value plots of the boxplots shown in Figure \ref{kkewbox}
%  (transformed durations of 135,000 Internet sessions, grouped by ranges of
%  (transformed) byte lengths).}
%  \label{kkewlv}

%\end{figure}

The standard letter value display stops with that letter value having depth = 1 (i.e., the extremes). In many cases, these extremes could lie far from the rest of the sample, particularly if they are outliers. Just as the whiskers in the conventional boxplot extend only to the adjacent values (observations just inside the inner fences, which can be the extremes in samples with no labeled outliers), the number of boxes in a letter-value plot need not extend to the last box corresponding to the extremes. We need a rule to determine the number of boxes to show in a letter-value plot, which will determine the number of labeled outliers. In this section, we consider four proposals for such a rule.

In many of the displays in \textit{Exploratory Data Analysis}, Tukey identified 5--8 extreme points. As a rough guideline, we can choose the extent of the letter-value plot display so that the last set of boxes encompasses all but the 5--8 most extreme observations. Recall that the depth of the $k^{th}$ letter value, $d_k$, is defined in terms of the previous depth: $d_k = (1 + \lfloor d_{k-1} \rfloor)/2$, which implies that $2 d_{k} -1 \leq d_{k-1} \leq 2 d_k - (1/2)$. If we stop the letter-value plot display at $LV_k$ where $k = \lfloor \log_2 n \rfloor - 3$, then we can expect to label 5--8 observations in each tail. For samples of size 10,000 as in Figure~\ref{stackbox}, $k = \lfloor log_2 10000 \rfloor - 4$ = 13 -- 4 = 9, so 9 letter values beyond the median are shown (F, E, D, C, B, A, Z, Y, X -- i.e., down to tail area of roughly 1/1024 $\approx$ 0.001). For the 3068 continental U.S.\ county populations, $k = \lfloor log_2 3068 \rfloor - 4$ = 11 -- 4 = 7, so Figure~\ref{kkewbox} shows 7 letter values (M, F, E, D, C, B, A).

An alternative criterion fixes the number of labeled outliers as a percentage of the overall sample size. Letting $p$ denote this proportion, the last set of boxes to be drawn ends with depths

\begin{equation}
k = \lfloor \log_2 n \rfloor - \lfloor \log_2 (np) \rfloor + 1
\end{equation}

\noindent In effect, conventional boxplots use this rule, with $p = 0.007$. This criterion results in the same rule as the previous rule for the samples in Figure~\ref{stackbox} ($n = 10,000$) when $p$ lies between 0.004 and 0.006 (0.4--0.6\%), and in Figure \ref{lvpops} ($n = 3068$) when $p$ lies between 0.011 and 0.020 (1.1--2.0\%).

A third approach is a rule in which the final $k$ is based on the ``trustworthiness'' of the $k^{th}$ letter value as an estimate of the corresponding population quantile. ``Trustworthiness'' can be characterized by the approximate 95\% confidence interval around a given letter value: if the interval overlaps that for the subsequent letter value, then the uncertainty for the given letter value is high enough that we will not display it. Thus, boxes are shown for those letter values whose approximate 95\% confidence intervals exclude the neighboring letter values. Since a letter value can be viewed as the median between the extreme and the previous letter value, and since an approximate $1-\alpha$ confidence interval for the median of $m$ values (with $m > 10$) has approximately $0.5 \sqrt{m} z_{1-\alpha/2}$ observations on both sides of the sample median (rounding to the nearest integer), where $z_{1-\alpha/2}$ is the ${1-\alpha/2}$ quantile of a standard Gaussian distribution (\citet[161]{ha.order}, based on the Gaussian approximation to the binomial distribution), this third criterion leads to a particularly straightforward rule.

%% this rule might be too strict for our purposes. I'll use just one CI and the letter value for rule #3 [HH]
%Consider the upper $k^{th}$ letter value, $LV_k$.  If its
%upper 95\% confidence limit does not extend beyond the 
%lower 95\% confidence limit for the next letter value, $LV_{k+1}$,
%we continue to $LV_{k+2}$; otherwise, the box corresponding to 
%$LV_k$ is the last box shown.  
%Since approximately $d_{k+1}$ observations lie 
%between $LV_k$ and $LV_{k+1}$, 
%and the upper 95\% limit for $LV_k$ (respectively, $LV_{k+1}$) has roughly 
%$\sqrt{d_{k-1}} \approx \sqrt{2 d_k }$ (respectively, $\sqrt{d_k}$)
%observations, this principle requires
%$\sqrt{2 d_k} + \sqrt{d_k} < d_{k+1} \approx d_k / 2$, or $d_k > 31.2$.
%A rule such as this one with 95\% confidence level often leads to
%labeling 5--8 of the most extreme observations on each side,
%surprisingly consistent with many of the displays in \textit{EDA}.
%[KK: ??? -- it would be more if my calculations are correct. And then the
%next sentence would not be right either, nor the subsequent paragraph.
%\textbf{Please check}]


Consider the upper $k^{th}$ letter value, $LV_k$. If its upper 95\% confidence limit does not extend beyond the next letter value, $LV_{k+1}$, we continue to the next letter value, $LV_{k+1}$; otherwise, the box corresponding to $LV_k$ is the last box shown. Since approximately $d_{k+1}$ observations lie between $LV_k$ and $LV_{k+1}$, and the upper 95\% limit for $LV_k$ has roughly $\sqrt{d_{k-1}} \approx \sqrt{2 d_k }$ observations, this principle requires $\sqrt{2 d_k} < d_{k+1} \approx d_k / 2$, or $d_k > 8$. A rule such as this one with 95\% confidence level often leads to labeling 5--8 of the most extreme observations on each side, surprisingly consistent with many of the displays in \citet{eda}.

Generally, the third rule suggests showing $k$ ``trustworthy'' LVs where $d_k > 2 z_{1-\alpha/2}^2 $, leading to the following stopping criterion:

\begin{equation}
k =  \left \lfloor \log_2 (n) - \log_2 
   \left(2  z_{1-\alpha/2}^2 \right) \right \rfloor + 1
\end{equation}

\noindent This third stopping rule has the obvious advantage that it provides a simple, distribution-free solution. Neither the overall sample size, nor any distribution-related characteristic such as skewness or kurtosis, affects the rule. When $\alpha = 0.05$ (95\% point-wise confidence), the rule leads to showing only those letter values whose depths are at least 10 (i.e., labeling 5--8 observations on each side). Because the first rule is a special case of this third rule, we will consider the use of only stopping rules 2 and 3. Note that $k = 7$ when $n$ is between 492 and 983, which corresponds to letter value A (Gaussian tail area 0.78\%). When $n$ is between 984 and 1966, $k = 8$, corresponding to letter value Z (Gaussian tail area 0.39\%), which is very close to the expected percentage of outliers from a Gaussian sample that are labeled by the conventional boxplot rule (Gaussian tail area 0.35\%).

% KK: I think we need more discussion about the differences 
% between rules 2 and 3, esp since they give diff answers
% depending on $p$.  I also think we'd better number those 2 eqns 
% for later reference.

A fourth rule is a variant of the previous rule, but assesses ``trustworthiness'' in terms of the standard error of the letter value. Table~\ref{tbl:letter-values} shows \texttt{SEfactor}, the factor used for the asymptotic standard error of the letter value for a Gaussian population:

\begin{equation}
SE(LV_i) \approx \sigma \sqrt{p_i \cdot (1 - p_i)/ n} / \phi(\Phi^{-1}(p_i)) 
 = (SEfactor) \sigma / \sqrt{n} \, ,
 \, \, \, p_i = 2^{-i} \, .
\label{SELV}
\end{equation}

\noindent When $i = 2$ ($p_i = 0.25$, fourths) and $n = 120$, this standard error is approximately 0.125$\sigma$; when $n = 186$, it is 0.10$\sigma$, and when $n = 743$, it is 0.05$\sigma$. Thus, a rough 2-SE interval around the fourth is roughly 0.25$\sigma$, 0.2$\sigma$, or 0.1$\sigma$, respectively, as $n$ increases from 120 to 186 to 743. How many more letter values can be shown with the same level of uncertainty when $n$ increases? For illustration, consider only the last (and most stringent) criterion, where 2$SE$ $\approx$ 0.1$\sigma$. If $n \geq 1032$, the asymptotic 2-SE uncertainty in $LV_3$, the eighth (E), using the formula in (\ref{SELV}), does not exceed 0.1$\sigma$. For the same precision in $LV_4$ (sixteenth), one needs $n \geq 1550$.

Table~\ref{tbl:lv-error} lists the letter values and the ranges on $n$ for which the uncertainty displayed up to a given letter value does not exceed 0.5$\sigma$, 0.25$\sigma$, 0.20$\sigma$, and 0.10$\sigma$. For example, when $n$ = 10,000 and a 2-SD uncertainty around the letter value no greater than 0.20$\sigma$, one can show up to letter value 10 (X, 1/1024), but only up to letter value 7 (A, 1/128) for uncertainty of that does not exceed 0.10$\sigma$. Figure~\ref{figyy} plots the columns in Table~\ref{tbl:lv-error} on a $\log_10$ scale, which shows that the logarithm of the sample size is approximately linear in the letter value number. This rule is very similar to rule (1) when the desired uncertainty in the letter values does not exceed 0.25$\sigma$.

The different rules provide the user with choices depending on the desired precision in the letter values shown. The current implementation of the letter-value plot display uses rule 3 as a default option.

\begin{table}
  \begin{center}
  \begin{tabular}{lrrrrr}
    \toprule
      &  i &    0.5 &     .25 &     0.2 &      0.1 \\
    \midrule
    M &  1 &     25 &     101 &     157 &      628 \\
    F &  2 &     30 &     119 &     186 &      743 \\
    E &  3 &     41 &     165 &     258 &     1,032 \\
    D &  4 &     62 &     248 &     387 &     1,550 \\
    C &  5 &     98 &     391 &     611 &     2,445 \\[3pt]
    B &  6 &    160 &     640 &    1,000 &     3,999 \\
    A &  7 &    269 &    1,077 &    1,682 &     6,728 \\
    Z &  8 &    463 &    1,851 &    2,893 &    11,570 \\
    Y &  9 &    810 &    3,240 &    5,063 &    20,251 \\
    X & 10 &   1,438 &    5,752 &    8,988 &    35,953  \\[3pt]
    W & 11 &   2,583 &   10,333 &   16,146 &    64,584 \\
    V & 12 &   4,686 &   18,744 &   29,288 &   117,152 \\
    U & 13 &   8,570 &   34,282 &   53,565 &   214,260 \\
    T & 14 &  15,784 &   63,137 &   98,652 &   394,609 \\
    S & 15 &  29,246 &  116,983 &  182,785 &   731,141  \\[3pt]
    R & 16 &  54,470 &  217,880 &  340,437 &  1,361,748 \\
    Q & 17 & 101,914 &  407,654 &  636,960 &  2,547,840 \\
    P & 18 & 191,449 &  765,796 & 1,196,557 &  4,786,227 \\
    O & 19 & 360,931 & 1,443,726 & 2,255,822 &  9,023,287 \\
    N & 20 & 682,624 & 2,730,498 & 4,266,403 & 17,065,610 \\
    \bottomrule
    
  \end{tabular}
  \end{center}
  \caption{Letter values, depth, and sample size needed for 2-SE intervals of size 0.5 $\sigma$, 0.25 $\sigma$, 0.2 $\sigma$, and 0.1 $\sigma$, respectively }
  \label{tbl:lv-error}
\end{table}


\begin{figure}[hbtp]
  \centering
  \includegraphics[scale=.6,angle=270]{figyy}

  \caption{Plot of $\log_{10} n$ versus letter value number to ensure a 2-SD
  uncertainty in displayed letter values of no more than 0.50 (5, black), 0.25
  (3, red), 0.20 (green, 2), 0.10 (blue, 1). Fitted lines have slopes 0.25 and
  intercepts 0.754, 1.356, 1.550, and 2.152, respectively. Data from Table 4.}
  \label{figyy} 
\end{figure}

\section{Bivariate letter value plots}
\label{sec:bivariate}

\citet{bagplots} proposed the ``bagplot'' as a two-dimensional version of the boxplot, using location depths (introduced by \citet{tukey75}) to define analogues of the median and fourths, and then connecting the points corresponding to the fourth-depths via linear segments. 

The location depth $ldepth(p,Z)$ is defined for an arbitrary point $p \in \Reals^2$, relative to a set of $n$ points $Z$ = \{$z_i = (x_i, y_i)$, $i = 1,...,n$\}, as the smallest number of $z_i$'s contained in any closed halfplane with boundary line through $p$. That is, if one were to pass a line in the plane through $p$ and keep track of the smaller of the two numbers of $z_i$ on either side of the line as the line is rotated through every angle to its opposite side ($180^o$), then the location depth of that point $p$ relative to $Z$ is the smallest of all the numbers. The analog of the one-dimension median in two dimensions using location depth would thus be that point $p_M$ for which $ldepth(p_M, Z)$ is largest (e.g., $n/2$). If such a $p$ is not unique, then the ``depth median'' is defined as the ``center of gravity'' of all points $p$ for which $ldepth(p,Z)$ is largest. Recall that a property of the fourths for a univariate sample is that the interval between the lower and upper fourth contains one-half of the data. Thus, an analog of the box for the bagplot was defined as the convex hull of all points $p$ for which $ldepth(p,Z) \ge 1 +  \lfloor 0.5 \cdot  ldepth(p_M, Z) \rfloor$. Similarly,  successive letter areas are defined based purely on their depth as the convex hull of all points in the sample with $ldepth_i(p,Z) \ge 1 +  \lfloor 0.5 \cdot  ldepth_{i-1}(p, Z) \rfloor$.
Figure \ref{counties-bag} shows a side-by side comparison of a standard bagplot (left, \citet{bagplots}, implemented in \citet{aplpack}) of average temperatures in January by degree latitude of each of 3,068 US counties and a letter-value bagplot on the right..

Algorithms for conveniently fast computation of bivariate letter values for a bivariate letter-value plot is currently under development.

\begin{figure}[hbtp]
  \centering
  \includegraphics[width=0.5\linewidth]{images/counties-bag}%
  \includegraphics[width=0.5\linewidth]{images/counties-lvbag}

  \caption{Bagplot (left) and letter-value bagplot (right) of average January
  temperatures by degree latitude for 3,068 US counties. }

  \label{counties-bag} 

\end{figure}

\section{Summary}
\label{sec:summary}

Letter-value plots provide a natural extension of boxplots in situations where we are dealing with large amounts of data: just as boxplots, they are based on actual data values, rather than smoothed values or estimated densities. Letter-value plots convey further information about tail behavior beyond the whiskers. Simple stopping rules that do neither depend on the number of points nor their distribution, allow us to construct reliable plots that are less prone to over-interpretation when dealing with small number of points: rule \# 3 will ensure to only then draw a box for quartiles, if there are at least 16 data points present in the data. This is particularly useful in situations, such as shown in figure \ref{lvbox2}, where we are dealing with groups of very different sizes. On the other hand, for large data situations, fewer observations will be labeled as  as ``outliers'' 
compared to a conventional boxplot, where there is a fixed rate of outliers -- for a normal distribution it is approximately 0.7\%.
Letter values can naturally be extended to two dimensions by making use of the half-space depth. This gives rise to letter-value bagplots as a two dimensional extension of letter-value plots, providing a robust, data-based assessment of data concentration. 

%The advantages of the letter value boxplot are:
%
%\begin{itemize}
%\item they are based on actual data values 
%\item they are simple to compute from the letter value display
%\item they convey further information about tail behavior beyond the whiskers
%\item for large data sets, fewer observations are labeled as ``outliers'' 
%compared to a conventional boxplot (roughly 0.7\%)
%\item their construction does not depend on a smoothing parameter.
%\end{itemize} 

% \appendix
% \section{Implementation}
% 
% The Appendix contains the R code for implementing these letter-value boxplots. The code has been posted also on \texttt{http://statlib.cmu.edu}. Further information about the code and its implementation are available from the first author.
% 
% \begin{verbatim}
% LVboxplot <- function(x, k = NULL, perc = NULL, alpha = 0.95, horizontal = T,
%   col = T, ...) 
% \end{verbatim}
% 
% \begin{itemize}
% \item[x] vector of data values to be displayed
% \item[k] number of letter-value statistics shown.
% \item[perc] percentage of data points to be shown individually (as outliers) outside the letter-value boxes.  {\tt perc} is used only if {\tt k} is not specified.
% \item[alpha] significance level, if neither {\tt k} nor {\tt perc} is specified.  {\tt alpha} is used in Rule 3 for the number of boxes to show.  If used, confidence intervals around each letter value  excludes neighboring letter value at significance level {\tt alpha}.
% \end{itemize}
% 
% \noindent The function returns a list with three components:
% 
% \begin{itemize}
% \item[letter.val] matrix of values (lower and upper) of all {\tt k}
%   letter values, including depth of each.
% \item[conf.int] $2k-1 \times 2$ matrix of confidence intervals for 
%   all letter values using significance level as specified in {\tt alpha}.
% \item[outliers] list all identified points (outliers in standard boxplot).
% \end{itemize}

\bibliographystyle{asa}
\bibliography{references}
\end{document} 
